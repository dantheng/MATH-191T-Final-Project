{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Progress Report\n",
    "## Daniel Theng\n",
    "### Table of Contents\n",
    "   * Current Progress\n",
    "   * Questions\n",
    "   * Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Progress\n",
    "\n",
    "   So far progress has been good and I have gotten quite far. The first part of my proposal said that I was goinig to perform some exploratory data analysis and notice any obvious trends. I was having some difficulty with the plotting methods, so I skipped this portion for the time being. I original plan was to do a pairplot, but when I created, because of the number of features in the data each individual plot was much too small to compare anything. \n",
    "   \n",
    "   Moving on, I was able to create the 3 models I was planning to use; Logistic Regression, Random Forest, and Support Vector Classifier. Using train_test_split, I split the data into training and test dataframes and fit and scored each of the models. \n",
    "   \n",
    "   Ranking each of the models, Random forest came out on top with an accuracy of 70%, Logistic Regression as a close second with 68%, and the Support Vector Classifier falling to last with an accuracy of 58%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "   The first thing I would like to know is why the Support Vector Classifer did so much worst than the other models. \n",
    "   \n",
    "   Another issue is to somehow get pairplot to work so that I can see the plots more clearly. \n",
    "   \n",
    "   Furthermore, I would like to know which features are the most important to the model and if it is possible to remove some features, while retaining most of the accuracy.\n",
    "   \n",
    "   Lastly, since my accuracy wasn't that great I would like to increase my accuracy a little. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions\n",
    "\n",
    "Here is my plan to address each of the issues discussed above:\n",
    "1. Do more research into support bector classifiers and the mathematical mechanism behind the model and compare it to the other models and see what is different about it that makes it perform worst on this data specifically. In turn, I will also find out why the Logistic Regression and Random Forest model were so more successful. \n",
    "2. My first instinct is to dive into the documentation for pairplot and see if I can alter the plot size somehow. If that search isn't fruitful, then I will try to use another plotting package to create the plot. As a last resort, I can split the data up so that each pairplot only deals with 4 features at a time. \n",
    "3. I know there is a feature importance attribute for Random Forest models so that would be able to give me information on which features were the most important to the model. I would need to research to see if there is a comparable attribute for Logistic Regression and Support Vector Classifier models. Then I would try to train new models gradually removing the features contributing the least to the models and record the accuracies of the models each time I remove an attribute\n",
    "4. This is probably the most difficult part of the project. I would have to use the data to engineer new feaatures. I have some ideas that might work like including a BMI feature calculated from the weight and height features and creating a hypertension feature calculated from the diastolic and systolic blood pressures. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
